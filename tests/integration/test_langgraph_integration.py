"""
Integration tests for the LangGraph system components.
"""
import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch
from datetime import datetime, timezone

from app.models.conversation import create_orchestration_state
from app.agents.jovani_vazquez import create_jovani_vazquez
from app.graphs.orchestrator import execute_orchestration_cycle
from app.graphs.character_workflow import execute_character_workflow
from app.services.dependency_container import DependencyContainer

@pytest.fixture
def real_dependency_container():
    """Create a dependency container with real AI provider."""
    container = DependencyContainer({
        "ai_provider": "claude",  # Use real Claude AI
        "news_provider": "mock",  # Mock external news
        "twitter_provider": "mock",  # Mock external Twitter
        "orchestration": "langgraph"  # Use real LangGraph
    })
    return container


class TestLangGraphSystemIntegration:
    """Test integration between LangGraph system components."""
    
    @pytest.mark.asyncio
    async def test_full_news_discovery_and_engagement_flow(self, sample_news_items, real_dependency_container):
        """Should execute complete news discovery and engagement flow with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create orchestration state
        orchestration_state = create_orchestration_state(["jovani_vazquez"])
        
        # Add news items to queue
        for news in sample_news_items:
            orchestration_state.pending_news_queue.append(news)
        
        # Execute orchestration cycle with real AI
        result = await execute_orchestration_cycle(
            news_items=[],
            existing_state=orchestration_state
        )
        
        # Verify orchestration result
        assert result["success"] is True
        assert "orchestration_state" in result
        assert "character_reactions" in result
        
        # Check that news items were processed
        final_state = result["orchestration_state"]
        assert final_state.processed_news_count >= 0
    
    @pytest.mark.asyncio
    async def test_character_workflow_integration_with_orchestration(self, news_item_builder, real_dependency_container):
        """Should integrate character workflow with orchestration system using real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create character agent with real AI provider
        jovani_agent = create_jovani_vazquez(ai_provider=ai_provider)
        
        # Create news item
        news_item = news_item_builder\
            .with_id("integration_test")\
            .with_headline("Integration Test News")\
            .with_topics(["music", "entertainment"])\
            .with_relevance_score(0.8)\
            .build()
        
        # Execute character workflow with real AI
        workflow_result = await execute_character_workflow(
            character_agent=jovani_agent,
            input_context="¬°Breaking news! New Puerto Rican music festival announced in San Juan! üî•üéµ This is going to be brutal!",
            news_item=news_item,
            target_topic="music",
            is_new_thread=True
        )
        
        # Verify workflow result
        assert workflow_result["success"] is True
        # The response should be generated by real AI
        assert workflow_result["generated_response"] is not None
        assert len(workflow_result["generated_response"]) > 0
        
        # Verify AI response quality (should be in Spanish or contain Puerto Rican elements)
        if workflow_result["engagement_decision"].value == "engage":
            response_lower = workflow_result["generated_response"].lower()
            assert any(word in response_lower for word in ["puerto", "rico", "m√∫sica", "festival", "san juan", "brutal"])
        
        # Create orchestration state and add news
        orchestration_state = create_orchestration_state(["jovani_vazquez"])
        orchestration_state.pending_news_queue.append(news_item)
        
        # Execute orchestration cycle with real AI
        orchestration_result = await execute_orchestration_cycle(
            news_items=[],
            existing_state=orchestration_state
        )
        
        # Verify orchestration result
        assert orchestration_result["success"] is True
    
    @pytest.mark.asyncio
    async def test_thread_engagement_integration(self, thread_state_builder, news_item_builder, real_dependency_container):
        """Should integrate thread engagement with character workflow using real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create character agent with real AI provider
        jovani_agent = create_jovani_vazquez(ai_provider=ai_provider)
        
        # Create thread state
        thread_state = thread_state_builder\
            .with_thread_id("integration_thread")\
            .with_original_content("Original thread content")\
            .build()
        
        # Add existing replies
        thread_state.add_character_reply("other_character", "First reply")
        thread_state.add_character_reply("another_character", "Second reply")
        
        # Execute character workflow with thread context and real AI
        result = await execute_character_workflow(
            character_agent=jovani_agent,
            input_context="¬°Wepa! This music festival thread is getting wild! üî•üéµ",
            conversation_history=[],
            target_topic="music",
            thread_id="integration_thread",
            thread_context="Thread discussion context",
            is_new_thread=False,
            thread_engagement_state=thread_state
        )
        
        # Verify result
        assert result["success"] is True
        # The response should be generated by real AI
        assert result["generated_response"] is not None
        assert len(result["generated_response"]) > 0
        
        # Verify thread state was updated (only if character decided to engage)
        if result.get("engagement_decision") == "engage":
            assert "jovani_vazquez" in thread_state.character_replies
        else:
            # If character decided not to engage, thread state should not be updated
            assert "jovani_vazquez" not in thread_state.character_replies
    
    @pytest.mark.asyncio
    async def test_personality_data_integration(self, jovani_personality, news_item_builder, real_dependency_container):
        """Should integrate personality data throughout the system with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create character agent with real AI provider
        jovani_agent = create_jovani_vazquez(ai_provider=ai_provider)
        
        # Verify personality data integration
        assert jovani_agent.personality_data.character_name == jovani_personality.character_name
        assert jovani_agent.personality_data.signature_phrases == jovani_personality.signature_phrases
        assert jovani_agent.personality_data.topic_weights == jovani_personality.topic_weights
        
        # Create news item relevant to personality
        news_item = news_item_builder\
            .with_id("personality_test")\
            .with_headline("Music Festival Announcement")\
            .with_topics(["music", "entertainment", "festival"])\
            .with_relevance_score(0.9)\
            .build()
        
        # Execute character workflow with real AI
        result = await execute_character_workflow(
            character_agent=jovani_agent,
            input_context="¬°Incre√≠ble! Major music festival coming to Puerto Rico! üî•üéµ This is exactly what we need!",
            news_item=news_item,
            target_topic="music",
            is_new_thread=True
        )
        
        # Verify result uses personality data with real AI
        assert result["success"] is True
        # The response should be generated by real AI
        assert result["generated_response"] is not None
        assert len(result["generated_response"]) > 0
        
        # Verify AI response reflects personality (should contain signature phrases or cultural elements)
        if result["engagement_decision"].value == "engage":
            response_lower = result["generated_response"].lower()
            # Should contain personality-driven content
            assert any(word in response_lower for word in ["puerto", "rico", "m√∫sica", "festival", "incre√≠ble", "brutal"])


class TestRealisticNewsDiscoveryFlow:
    """Test realistic news discovery and processing flow with real AI."""
    
    @pytest.mark.asyncio
    async def test_realistic_news_discovery_sequence(self, news_item_builder, real_dependency_container):
        """Should process news items in realistic discovery sequence with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create orchestration state
        orchestration_state = create_orchestration_state(["jovani_vazquez"])
        
        # Create news items with different characteristics
        news_items = [
            news_item_builder\
                .with_id("breaking_news")\
                .with_headline("Breaking: Major Music Festival Announced")\
                .with_topics(["music", "entertainment", "festival"])\
                .with_relevance_score(0.9)\
                .build(),
            news_item_builder\
                .with_id("local_news")\
                .with_headline("Local Traffic Update")\
                .with_topics(["traffic", "local", "transportation"])\
                .with_relevance_score(0.5)\
                .build(),
            news_item_builder\
                .with_id("cultural_news")\
                .with_headline("Cultural Heritage Restoration")\
                .with_topics(["culture", "heritage", "history"])\
                .with_relevance_score(0.7)\
                .build()
        ]
        
        # Process news items one by one (realistic discovery) with real AI
        for i, news in enumerate(news_items):
            # Add news item to queue
            orchestration_state.pending_news_queue.append(news)
            
            # Execute orchestration cycle with real AI
            result = await execute_orchestration_cycle(
                news_items=[],
                existing_state=orchestration_state
            )
            
            # Verify each cycle completed successfully
            assert result["success"] is True, f"Orchestration cycle {i} failed: {result.get('error_details')}"
        
        # Verify final processed news count after all cycles
        final_result = await execute_orchestration_cycle(
            news_items=[],
            existing_state=orchestration_state
        )
        assert final_result["success"] is True
        assert final_result["orchestration_state"].processed_news_count >= 1  # At least one news item should be processed
    
    @pytest.mark.asyncio
    async def test_news_priority_processing(self, news_item_builder, real_dependency_container):
        """Should process news items based on priority and relevance with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create orchestration state
        orchestration_state = create_orchestration_state(["jovani_vazquez"])
        
        # Create news items with different priorities
        high_priority = news_item_builder\
            .with_id("high_priority")\
            .with_headline("Breaking: Major Music Festival")\
            .with_topics(["music", "entertainment"])\
            .with_relevance_score(0.9)\
            .build()
        
        low_priority = news_item_builder\
            .with_id("low_priority")\
            .with_headline("Minor Local Event")\
            .with_topics(["local", "minor"])\
            .with_relevance_score(0.3)\
            .build()
        
        # Add both news items
        orchestration_state.pending_news_queue.append(high_priority)
        orchestration_state.pending_news_queue.append(low_priority)
        
        # Execute orchestration cycle with real AI
        result = await execute_orchestration_cycle(
            news_items=[],
            existing_state=orchestration_state
        )
        
        # Verify processing completed
        assert result["success"] is True
        assert result["orchestration_state"].processed_news_count >= 0


class TestThreadBasedEngagementFlow:
    """Test thread-based engagement flow with real AI."""
    
    @pytest.mark.asyncio
    async def test_thread_conversation_flow(self, thread_state_builder, news_item_builder, real_dependency_container):
        """Should handle thread conversation flow with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create character agent with real AI provider
        jovani_agent = create_jovani_vazquez(ai_provider=ai_provider)
        
        # Create thread state
        thread_state = thread_state_builder\
            .with_thread_id("conversation_thread")\
            .with_original_content("Original music festival discussion")\
            .build()
        
        # Add multiple character replies
        thread_state.add_character_reply("user1", "This festival is going to be amazing!")
        thread_state.add_character_reply("user2", "I can't wait for the lineup announcement!")
        thread_state.add_character_reply("user3", "Puerto Rican music culture is incredible!")
        
        # Execute character workflow with real AI
        result = await execute_character_workflow(
            character_agent=jovani_agent,
            input_context="¬°Wepa! This thread is getting wild! üî•üéµ",
            conversation_history=[],
            target_topic="music",
            thread_id="conversation_thread",
            thread_context="Music festival discussion thread",
            is_new_thread=False,
            thread_engagement_state=thread_state
        )
        
        # Verify result
        assert result["success"] is True
        assert result["generated_response"] is not None
        assert len(result["generated_response"]) > 0
        
        # Verify thread-aware response quality
        if result["engagement_decision"].value == "engage":
            response_lower = result["generated_response"].lower()
            # Should reference thread context
            assert any(word in response_lower for word in ["festival", "m√∫sica", "puerto", "rico", "thread", "discussion"])
    
    @pytest.mark.asyncio
    async def test_thread_rate_limiting_integration(self, thread_state_builder, real_dependency_container):
        """Should handle thread rate limiting with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create character agent with real AI provider
        jovani_agent = create_jovani_vazquez(ai_provider=ai_provider)
        
        # Create thread state with many replies (rate limiting scenario)
        thread_state = thread_state_builder\
            .with_thread_id("rate_limit_thread")\
            .with_original_content("Original content")\
            .build()
        
        # Add many character replies to simulate rate limiting
        for i in range(10):
            thread_state.add_character_reply(f"user_{i}", f"Reply {i}")
        
        # Execute character workflow with real AI
        result = await execute_character_workflow(
            character_agent=jovani_agent,
            input_context="Test thread engagement",
            conversation_history=[],
            target_topic="test",
            thread_id="rate_limit_thread",
            thread_context="Rate limiting test",
            is_new_thread=False,
            thread_engagement_state=thread_state
        )
        
        # Verify result (may decide not to engage due to rate limiting)
        assert result["success"] is True
        assert result["engagement_decision"] is not None


class TestSystemErrorHandling:
    """Test system error handling with real AI."""
    
    @pytest.mark.asyncio
    async def test_ai_provider_failure_recovery(self, news_item_builder, real_dependency_container):
        """Should handle AI provider failures gracefully."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Test with invalid input that might cause AI provider issues
        try:
            # Create character agent with real AI provider
            jovani_agent = create_jovani_vazquez(ai_provider=ai_provider)
            
            # Create news item
            news_item = news_item_builder\
                .with_id("error_test")\
                .with_headline("Test News")\
                .with_topics(["test"])\
                .with_relevance_score(0.5)\
                .build()
            
            # Execute character workflow with potentially problematic input
            result = await execute_character_workflow(
                character_agent=jovani_agent,
                input_context="",  # Empty context might cause issues
                news_item=news_item,
                target_topic="test",
                is_new_thread=True
            )
            
            # Should handle gracefully
            assert result["success"] is True or result["success"] is False
            assert "error_details" in result or "generated_response" in result
            
        except Exception as e:
            # Should handle errors gracefully
            assert "error" in str(e).lower() or "invalid" in str(e).lower()
    
    @pytest.mark.asyncio
    async def test_invalid_data_handling(self, news_item_builder, real_dependency_container):
        """Should handle invalid data gracefully with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        try:
            # Create character agent with real AI provider
            jovani_agent = create_jovani_vazquez(ai_provider=ai_provider)
            
            # Create news item with invalid data
            news_item = news_item_builder\
                .with_id("invalid_test")\
                .with_headline("")\
                .with_topics([])\
                .with_relevance_score(-1)\
                .build()
            
            # Execute character workflow with invalid data
            result = await execute_character_workflow(
                character_agent=jovani_agent,
                input_context="Test with invalid data",
                news_item=news_item,
                target_topic="",
                is_new_thread=True
            )
            
            # Should handle gracefully
            assert result["success"] is True or result["success"] is False
            
        except Exception as e:
            # Should handle errors gracefully
            assert "error" in str(e).lower() or "invalid" in str(e).lower()


class TestPerformanceAndScalability:
    """Test performance and scalability with real AI."""
    
    @pytest.mark.asyncio
    async def test_large_news_queue_processing(self, news_item_builder, real_dependency_container):
        """Should handle large news queue with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create orchestration state
        orchestration_state = create_orchestration_state(["jovani_vazquez"])
        
        # Create many news items
        for i in range(5):  # Limit to 5 for performance testing
            news_item = news_item_builder\
                .with_id(f"large_queue_{i}")\
                .with_headline(f"News Item {i}")\
                .with_topics(["test"])\
                .with_relevance_score(0.5)\
                .build()
            orchestration_state.pending_news_queue.append(news_item)
        
        # Execute orchestration cycle with real AI
        result = await execute_orchestration_cycle(
            news_items=[],
            existing_state=orchestration_state
        )
        
        # Verify processing completed
        assert result["success"] is True
        assert result["orchestration_state"].processed_news_count >= 0
    
    @pytest.mark.asyncio
    async def test_multiple_character_processing(self, news_item_builder, real_dependency_container):
        """Should handle multiple character processing with real AI."""
        # Get real AI provider
        ai_provider = real_dependency_container.get_ai_provider()
        
        # Create orchestration state with multiple characters
        orchestration_state = create_orchestration_state(["jovani_vazquez", "other_character"])
        
        # Create news item
        news_item = news_item_builder\
            .with_id("multi_character_test")\
            .with_headline("Multi-Character Test News")\
            .with_topics(["test"])\
            .with_relevance_score(0.7)\
            .build()
        
        orchestration_state.pending_news_queue.append(news_item)
        
        # Execute orchestration cycle with real AI
        result = await execute_orchestration_cycle(
            news_items=[],
            existing_state=orchestration_state
        )
        
        # Verify processing completed
        assert result["success"] is True
        assert result["orchestration_state"].processed_news_count >= 0 